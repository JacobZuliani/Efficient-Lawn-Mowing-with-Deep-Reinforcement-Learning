{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from visualization import visualize_environment\n",
    "from random import randrange\n",
    "from os import startfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment():\n",
    "    # this class defines what actions are available, what they do, and how they modify the environment\n",
    "    # this class keeps track of the agents attributes including loss\n",
    "\n",
    "    def __init__(self, agent_position, agent_direction, environment_shape):\n",
    "        # position is a 2 element list containing a coordinate pair [x,y]\n",
    "        # direction is a cardinal direction represented by one of the four characters N, S, E, W\n",
    "        # environment_shape is the shape of the environment matrix\n",
    "        \n",
    "        self.environment_shape = environment_shape\n",
    "        self.agent_position = agent_position\n",
    "        self.agent_direction = agent_direction\n",
    "        self.moves = 0\n",
    "        \n",
    "    def __can_occupy(self, tile):\n",
    "        # can the agent occupy tile?\n",
    "                \n",
    "        return tile[0] != '9' # True if tile is not wood\n",
    "    \n",
    "    def __cut_the_grass(self, environment_state):        \n",
    "        # if the current space is tall grass then cut it\n",
    "        if environment_state[self.agent_position[0], self.agent_position[1]][0] == '8': # if current space is tall grass\n",
    "            current_tile = environment_state[self.agent_position[0], self.agent_position[1]]\n",
    "            environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '1', 0) # replace with cut grass     \n",
    "        return environment_state\n",
    "    \n",
    "    def __modify_tile(self, tile, new_value, position):\n",
    "        # returns tile with new_value in position\n",
    "        # \"why dont you just use arrays instead of non mutable strings?\", mainly cause it makes one hot encoding easier but also cause\n",
    "        # I already did it this way and am only now realizing making a tensor of the lawn instead of the matrix may bave been the better way.\n",
    "        \n",
    "        # converting to an array is slow with numpy.fromstring and slow with python list() so I decided to just not convert it\n",
    "        if position == 0:\n",
    "            return new_value + tile[1] + tile[2]\n",
    "        elif position == 1:\n",
    "            return tile[0] + new_value + tile[2] \n",
    "        elif position == 2:\n",
    "            return tile[0] + tile[1] + new_value\n",
    "        else:\n",
    "            raise Exception('invalid tile index ' + position)\n",
    "        \n",
    "    def take_action(self, action, environment_state):\n",
    "        # takes the action that was recived and returns an updated environment state\n",
    "        \n",
    "        if action == 1:\n",
    "            updated_environment_state = self.advance(environment_state)\n",
    "        elif action == 2:\n",
    "            updated_environment_state = self.pivot_clockwise(environment_state)\n",
    "        elif action == 3:\n",
    "            updated_environment_state = self.pivot_counterclockwise(environment_state)\n",
    "        else:\n",
    "            raise Exception('invalid action_id ' + action)\n",
    "        self.moves += 1        \n",
    "        return updated_environment_state\n",
    "    \n",
    "    # below I define all actions the agent can take and how they modify the environment\n",
    "    def advance(self, environment_state):\n",
    "        # advance one space in the direction the agent is currently facing\n",
    "        # return updated environment state\n",
    "        \n",
    "        current_tile = environment_state[self.agent_position[0], self.agent_position[1]] # defining here for readability\n",
    "        \n",
    "        if self.agent_direction == 'N':\n",
    "            environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '1', 2) # exit from north\n",
    "            if self.agent_position[0]-1 != -1 and self.__can_occupy(environment_state[self.agent_position[0]-1, self.agent_position[1]]): # if next space can be occupied\n",
    "                self.agent_position[0] -= 1 # advance\n",
    "                current_tile = environment_state[self.agent_position[0], self.agent_position[1]] # redefine current tile since the agent moved\n",
    "                environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '2', 1) # exit from north # enter from south\n",
    "        elif self.agent_direction == 'S':\n",
    "            environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '2', 2) # exit from south\n",
    "            if self.agent_position[0]+1 != self.environment_shape[0] and self.__can_occupy(environment_state[self.agent_position[0]+1, self.agent_position[1]]): # if next space can be occupied\n",
    "                self.agent_position[0] += 1 # advance\n",
    "                current_tile = environment_state[self.agent_position[0], self.agent_position[1]] # redefine current tile since the agent moved\n",
    "                environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '1', 1) # enter from north\n",
    "        elif self.agent_direction == 'E':\n",
    "            environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '3', 2) # exit from east\n",
    "            if self.agent_position[1]+1 != self.environment_shape[1] and self.__can_occupy(environment_state[self.agent_position[0], self.agent_position[1]+1]): # if next space can be occupied\n",
    "                self.agent_position[1] += 1 # advance\n",
    "                current_tile = environment_state[self.agent_position[0], self.agent_position[1]] # redefine current tile since the agent moved\n",
    "                environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '4', 1) # enter from west\n",
    "        elif self.agent_direction == 'W':\n",
    "            environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '4', 2) # exit from west\n",
    "            if self.agent_position[1]-1 != -1 and self.__can_occupy(environment_state[self.agent_position[0], self.agent_position[1]-1]): # if next space can be occupied\n",
    "                self.agent_position[1] -= 1 # advance\n",
    "                current_tile = environment_state[self.agent_position[0], self.agent_position[1]] # redefine current tile since the agent moved\n",
    "                environment_state[self.agent_position[0], self.agent_position[1]] = self.__modify_tile(current_tile, '3', 1) # enter from east\n",
    "        else:\n",
    "            raise Exception('unknown direction')\n",
    "        environment_state = self.__cut_the_grass(environment_state) # if the current space is tall grass then cut it\n",
    "        return environment_state\n",
    "    \n",
    "    def pivot_clockwise(self, environment_state):\n",
    "        # rotate direction by 90° clockwise\n",
    "        # return updated environment state\n",
    "        \n",
    "        if self.agent_direction == 'N':\n",
    "            self.agent_direction = 'E'\n",
    "        elif self.agent_direction == 'S':\n",
    "            self.agent_direction = 'W'\n",
    "        elif self.agent_direction == 'E':\n",
    "            self.agent_direction = 'S'\n",
    "        elif self.agent_direction == 'W':\n",
    "            self.agent_direction = 'N'\n",
    "        else:\n",
    "            raise Exception('unknown direction')        \n",
    "\n",
    "        return environment_state\n",
    "        \n",
    "    def pivot_counterclockwise(self, environment_state):\n",
    "        # rotate direction by 90° counterclockwise\n",
    "        # return updated environment state\n",
    "        \n",
    "        if self.agent_direction == 'N':\n",
    "            self.agent_direction = 'W'\n",
    "        elif self.agent_direction == 'S':\n",
    "            self.agent_direction = 'E'\n",
    "        elif self.agent_direction == 'E':\n",
    "            self.agent_direction = 'N'\n",
    "        elif self.agent_direction == 'W':\n",
    "            self.agent_direction = 'S'\n",
    "        else:\n",
    "            raise Exception('unknown direction')        \n",
    "        \n",
    "        return environment_state\n",
    "    \n",
    "    # below I define all getters which are just used to interface with the simulation class\n",
    "    def get_done_condition(self, environment_state):\n",
    "        # returns true if the environment is complete (entire lawn is mowed)\n",
    "        \n",
    "        return ('800' not in environment_state) # if there are no tall grass blocks then lawn is mowed\n",
    "    \n",
    "    def get_action_space(self):\n",
    "        # returns tuple of possible actions as numbers\n",
    "        # mapping:\n",
    "        # 1 = 'advance'\n",
    "        # 2 = 'pivot_clockwise'\n",
    "        # 3 = 'pivot_counterclockwise'\n",
    "        \n",
    "        return (1,2,3)\n",
    "        \n",
    "    def get_position(self):\n",
    "        # return agents current position\n",
    "        return self.x, self.y\n",
    "    \n",
    "    def get_direction(self):\n",
    "        # return agents current direction\n",
    "        return self.direction\n",
    "    \n",
    "    def get_reward(self):\n",
    "        # return agents current reward\n",
    "        return self.moves\n",
    "    \n",
    "class simulation():\n",
    "    # this class manages the simulation for any agent or environment\n",
    "\n",
    "    def __init__(self, starting_environment_state, environment, visualization):\n",
    "        # environment is a class instance defining what the agent can and can't do\n",
    "        # visualization is an instance of visualize_environment from visualization.py\n",
    "        # starting_environment_state is the starting view of the environment (matrix of strings)\n",
    "        \n",
    "        # below variables should not be modified\n",
    "        self.starting_visualization = visualization # class instance\n",
    "        self.starting_environment = environment # class instance\n",
    "        self.starting_environment_state = starting_environment_state # matrix of strings\n",
    "        self.reset()\n",
    "        \n",
    "    def get_action_space(self):\n",
    "        # returns a tuple of functions where each function defines the action\n",
    "        \n",
    "        return self.environment.get_action_space()\n",
    "    \n",
    "    def get_simulation_history_visualization(self, file_name, fps):\n",
    "        # outputs an mp4 file of the agent mowing the lawn\n",
    "        \n",
    "        self.visualization.output_history(file_name, fps)\n",
    "        \n",
    "    def display_last_env_state(self):\n",
    "        # displays the last environment state of the simulation\n",
    "        \n",
    "        self.visualization.display_last_environment_state()\n",
    "    \n",
    "    def reset(self):\n",
    "        # resets environment to the way it was when the simulation was initalized\n",
    "        # returns the starting environment state\n",
    "        \n",
    "        # everything needs to be copied (instead of creating another pointer) to avoid modifying the original\n",
    "        self.current_environment_state = deepcopy(self.starting_environment_state)\n",
    "        self.visualization = deepcopy(self.starting_visualization)\n",
    "        self.environment = deepcopy(self.starting_environment)\n",
    "        self.reward = 0\n",
    "        return self.current_environment_state\n",
    "        \n",
    "    def step(self, action):\n",
    "        # competes single environment step where agent takes action, then recives observation, reward, and whether they are done\n",
    "        \n",
    "        self.current_environment_state = self.environment.take_action(action, self.current_environment_state) # take action to get next environment state\n",
    "        self.reward = self.environment.get_reward() # obtain current reward\n",
    "        self.visualization.recive_environment_state(self.current_environment_state) # update visualization\n",
    "        # return updated environment state, reqard, and done_condition\n",
    "        return self.current_environment_state, self.reward, self.environment.get_done_condition(self.current_environment_state)\n",
    "    \n",
    "def show_environment_state(environment_state):\n",
    "    # shows any environment state inde\n",
    "    \n",
    "    visualization = visualize_environment()\n",
    "    visualization.recive_environment_state(starting_environment_state)\n",
    "    visualization.display_last_environment_state(ipynb = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_environment_state = np.array([\n",
    "    ['900','900','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','900','900','900','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','900','900','900','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','200','200','200','200','900','900','900','900','900','900','900','900','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','200','200','200','200','900','900','900','900','900','900','900','900','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','200','200','800','800','100','800','800','800','900','900','900','900','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','200','200','800','800','800','800','800','800','900','900','900','900','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','200','200','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','200','200','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['200','200','200','200','200','200','800','800','800','800','900','900','800','800','800','800','800','800','900', '900', '800', '800'],\n",
    "    ['200','200','200','200','200','200','800','800','800','800','900','900','800','800','800','800','800','800','900', '900', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800'],\n",
    "    ['800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800','800', '800', '800', '800']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_environment_state = np.array([\n",
    "    ['900','900','800','800','800','800','800'],\n",
    "    ['800','800','800','800','800','800','800'],\n",
    "    ['800','800','800','800','800','800','800']])\n",
    "#show_environment_state(starting_environment_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = simulation(starting_environment_state, environment([0,2], 'S', starting_environment_state.shape), visualize_environment())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = sim.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    observation, reward, done = sim.step(randrange(1,4)) # take random action\n",
    "print(reward)\n",
    "sim.get_simulation_history_visualization(\"random_agent_small_env.mp4\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startfile('random_agent_small_env.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
